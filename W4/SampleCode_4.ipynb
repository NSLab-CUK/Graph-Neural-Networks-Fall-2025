{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLC_OvrmM7gc"
      },
      "source": [
        "## Install library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q38BTpDnM7PQ",
        "outputId": "dea00a43-f341-470c-dc7e-ac9b6495fa13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.8.0+cpu.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.8.0%2Bcpu/torch_scatter-2.1.2%2Bpt28cpu-cp311-cp311-win_amd64.whl (425 kB)\n",
            "Installing collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2+pt28cpu\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.8.0+cpu.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.8.0%2Bcpu/torch_sparse-0.6.18%2Bpt28cpu-cp311-cp311-win_amd64.whl (769 kB)\n",
            "     ---------------------------------------- 0.0/769.7 kB ? eta -:--:--\n",
            "     ---------------------------------------- 0.0/769.7 kB ? eta -:--:--\n",
            "     ---------------------------------------- 0.0/769.7 kB ? eta -:--:--\n",
            "     ------------- -------------------------- 262.1/769.7 kB ? eta -:--:--\n",
            "     ---------------------------------------- 769.7/769.7 kB 3.0 MB/s  0:00:00\n",
            "Requirement already satisfied: scipy in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from torch-sparse) (1.16.2)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from scipy->torch-sparse) (2.3.3)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.18+pt28cpu\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.8.0+cpu.html\n",
            "Collecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.8.0%2Bcpu/torch_cluster-1.6.3%2Bpt28cpu-cp311-cp311-win_amd64.whl (525 kB)\n",
            "     ---------------------------------------- 0.0/525.7 kB ? eta -:--:--\n",
            "     ---------------------------------------- 0.0/525.7 kB ? eta -:--:--\n",
            "     ---------------------------------------- 0.0/525.7 kB ? eta -:--:--\n",
            "     ------------------- -------------------- 262.1/525.7 kB ? eta -:--:--\n",
            "     ---------------------------------------- 525.7/525.7 kB 1.9 MB/s  0:00:00\n",
            "Requirement already satisfied: scipy in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from torch-cluster) (1.16.2)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from scipy->torch-cluster) (2.3.3)\n",
            "Installing collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.6.3+pt28cpu\n",
            "Requirement already satisfied: ogb in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (1.3.6)\n",
            "Requirement already satisfied: torch>=1.6.0 in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from ogb) (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.16.0 in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from ogb) (2.3.3)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from ogb) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from ogb) (1.7.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from ogb) (2.3.2)\n",
            "Requirement already satisfied: six>=1.12.0 in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from ogb) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from ogb) (2.5.0)\n",
            "Requirement already satisfied: outdated>=0.2.0 in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from ogb) (0.2.2)\n",
            "Requirement already satisfied: setuptools>=44 in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from outdated>=0.2.0->ogb) (65.5.0)\n",
            "Requirement already satisfied: littleutils in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from outdated>=0.2.0->ogb) (0.2.4)\n",
            "Requirement already satisfied: requests in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from outdated>=0.2.0->ogb) (2.32.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from pandas>=0.24.0->ogb) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from pandas>=0.24.0->ogb) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from pandas>=0.24.0->ogb) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.8.0 in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from scikit-learn>=0.20.0->ogb) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from scikit-learn>=0.20.0->ogb) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from scikit-learn>=0.20.0->ogb) (3.6.0)\n",
            "Requirement already satisfied: filelock in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from torch>=1.6.0->ogb) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from torch>=1.6.0->ogb) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from torch>=1.6.0->ogb) (1.14.0)\n",
            "Requirement already satisfied: networkx in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from torch>=1.6.0->ogb) (3.5)\n",
            "Requirement already satisfied: jinja2 in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from torch>=1.6.0->ogb) (3.1.6)\n",
            "Requirement already satisfied: fsspec in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from torch>=1.6.0->ogb) (2025.9.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from sympy>=1.13.3->torch>=1.6.0->ogb) (1.3.0)\n",
            "Requirement already satisfied: colorama in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from tqdm>=4.29.0->ogb) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from jinja2->torch>=1.6.0->ogb) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from requests->outdated>=0.2.0->ogb) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from requests->outdated>=0.2.0->ogb) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from requests->outdated>=0.2.0->ogb) (2025.8.3)\n",
            "Requirement already satisfied: umap-learn in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (0.5.9.post2)\n",
            "Requirement already satisfied: numpy>=1.23 in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from umap-learn) (2.3.3)\n",
            "Requirement already satisfied: scipy>=1.3.1 in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from umap-learn) (1.16.2)\n",
            "Requirement already satisfied: scikit-learn>=1.6 in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from umap-learn) (1.7.2)\n",
            "Requirement already satisfied: numba>=0.51.2 in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from umap-learn) (0.62.0)\n",
            "Requirement already satisfied: pynndescent>=0.5 in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from umap-learn) (0.5.13)\n",
            "Requirement already satisfied: tqdm in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from umap-learn) (4.67.1)\n",
            "Requirement already satisfied: llvmlite<0.46,>=0.45.0dev0 in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from numba>=0.51.2->umap-learn) (0.45.0)\n",
            "Requirement already satisfied: joblib>=0.11 in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from pynndescent>=0.5->umap-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from scikit-learn>=1.6->umap-learn) (3.6.0)\n",
            "Requirement already satisfied: colorama in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from tqdm->umap-learn) (0.4.6)\n",
            "Requirement already satisfied: seaborn in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (0.13.2)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from seaborn) (2.3.3)\n",
            "Requirement already satisfied: pandas>=1.2 in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from seaborn) (2.3.2)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from seaborn) (3.10.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.60.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in f:\\thien\\course_graph_2025\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.8.0+cpu.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-2.8.0+cpu.html\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-2.8.0+cpu.html\n",
        "!pip install -q torch-geometric\n",
        "!pip install ogb\n",
        "!pip install umap-learn\n",
        "!pip install seaborn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjTft0itNBdg"
      },
      "source": [
        "## Import library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "hYfLO-K1DBkB"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "f:\\Thien\\course_graph_2025\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import ModuleList\n",
        "from torch_cluster import random_walk\n",
        "\n",
        "from tqdm import tqdm\n",
        "from torch_geometric.nn import SAGEConv, GraphConv\n",
        "from torch_geometric.datasets import Flickr, Planetoid, Reddit\n",
        "from torch_geometric.loader import GraphSAINTRandomWalkSampler, ClusterData, ClusterLoader, NeighborLoader, NeighborSampler as RawNeighborSampler\n",
        "from torch_geometric.typing import WITH_TORCH_SPARSE\n",
        "from torch_geometric.utils import degree\n",
        "import torch_geometric.transforms as T\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "import os.path as osp\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import collections\n",
        "from pandas.core.common import flatten\n",
        "\n",
        "# importing obg datatset\n",
        "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator\n",
        "from pandas.core.common import flatten\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.set(rc={'figure.figsize':(16.7,8.27)})\n",
        "sns.set_theme(style=\"ticks\")\n",
        "import collections\n",
        "from scipy.special import softmax\n",
        "import umap\n",
        "\n",
        "import argparse\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWP90NRsNIDO"
      },
      "source": [
        "## Download dataset and retrieve information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed folder does not exist. Proceeding to download and process the dataset.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import os.path as osp\n",
        "import shutil\n",
        "\n",
        "# Define the path to the processed folder\n",
        "path = osp.join('data', 'Reddit', 'ogbn-products', 'processed')\n",
        "\n",
        "# Remove the processed folder if it exists\n",
        "if os.path.exists(path):\n",
        "    shutil.rmtree(path)\n",
        "    print(\"Deleted the processed folder. The dataset will be re-downloaded and re-processed.\")\n",
        "else:\n",
        "    print(\"Processed folder does not exist. Proceeding to download and process the dataset.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sdwq2QUMNJ1k",
        "outputId": "9e36cf2d-11e5-440f-dda2-f6405cb0783e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PygNodePropPredDataset()\n",
            "Data(num_nodes=2449029, edge_index=[2, 123718280], x=[2449029, 100], y=[2449029, 1])\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import os.path as osp\n",
        "from ogb.nodeproppred import PygNodePropPredDataset\n",
        "import torch\n",
        "import torch_geometric.data.data\n",
        "import torch_geometric.data.storage\n",
        "\n",
        "# Create directory if it doesn't exist\n",
        "path = osp.join('data', 'Reddit')\n",
        "os.makedirs(path, exist_ok=True)\n",
        "\n",
        "# Allowlist necessary classes\n",
        "torch.serialization.add_safe_globals([\n",
        "    torch_geometric.data.data.DataEdgeAttr,\n",
        "    torch_geometric.data.data.DataTensorAttr,\n",
        "    torch_geometric.data.Data,\n",
        "    torch_geometric.data.storage.GlobalStorage  # Add GlobalStorage\n",
        "])\n",
        "\n",
        "# Load the dataset\n",
        "try:\n",
        "    dataset = PygNodePropPredDataset('ogbn-products', path)\n",
        "    # Verify dataset\n",
        "    print(dataset)\n",
        "    print(dataset[0])\n",
        "except Exception as e:\n",
        "    print(\"Error occurred:\", e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "nid6mVY1X3U2"
      },
      "outputs": [],
      "source": [
        "# split_idx contains a dictionary of train, validation and test node indices\n",
        "split_idx = dataset.get_idx_split()\n",
        "# predefined ogb evaluator method used for validation of predictions\n",
        "evaluator = Evaluator(name='ogbn-products')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7t_DXz8NOF2",
        "outputId": "ad1bd64c-5564-418c-ce5d-7122624b5897"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of training nodes: 196615\n",
            "Number of validation nodes: 39323\n",
            "Number of test nodes: 2213091\n"
          ]
        }
      ],
      "source": [
        "# lets check the node ids distribution of train, test and val\n",
        "print('Number of training nodes:', split_idx['train'].size(0))\n",
        "print('Number of validation nodes:', split_idx['valid'].size(0))\n",
        "print('Number of test nodes:', split_idx['test'].size(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "MXwUEr0nNPwG"
      },
      "outputs": [],
      "source": [
        "# loading the dataset\n",
        "data = dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create mask from split_idx\n",
        "train_idx = split_idx['train']\n",
        "valid_idx = split_idx['valid']\n",
        "test_idx = split_idx['test']\n",
        "\n",
        "data.train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "data.train_mask[train_idx] = True\n",
        "\n",
        "data.val_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "data.val_mask[valid_idx] = True\n",
        "\n",
        "data.test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "data.test_mask[test_idx] = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jov1jERjNRJf",
        "outputId": "c00e1e00-89d7-48b2-e157-d9efd7bb41cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of nodes in the graph: 2449029\n",
            "Number of edges in the graph: 123718280\n",
            "Node feature matrix with shape: torch.Size([2449029, 100])\n",
            "Graph connectivity in COO format with shape: torch.Size([2, 123718280])\n",
            "Target to train against : torch.Size([2449029, 1])\n",
            "Node feature length 100\n"
          ]
        }
      ],
      "source": [
        "# graph statistics of ogb-product graph\n",
        "print(\"Number of nodes in the graph:\", data.num_nodes)\n",
        "print(\"Number of edges in the graph:\", data.num_edges)\n",
        "print(\"Node feature matrix with shape:\", data.x.shape) # [num_nodes, num_node_features]\n",
        "print(\"Graph connectivity in COO format with shape:\", data.edge_index.shape) # [2, num_edges]\n",
        "print(\"Target to train against :\", data.y.shape)\n",
        "print(\"Node feature length\", dataset.num_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rT9xb3qiNTc9",
        "outputId": "404b1790-b373-454f-e3d5-22cceca805ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
              "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
              "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46])"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# checking the number of unique labels\n",
        "# there are 47 unique categories of product\n",
        "data.y.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "iCM-4aD0NVAv"
      },
      "outputs": [],
      "source": [
        "# load integer to real product category from label mapping provided inside the dataset\n",
        "df = pd.read_csv('data/Reddit/ogbn_products/mapping/labelidx2productcategory.csv.gz')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "fgtYJXp7NW_H"
      },
      "outputs": [],
      "source": [
        "# creating a dictionary of product category and corresponding integer label\n",
        "label_idx, prod_cat = df.iloc[: ,0].values, df.iloc[: ,1].values\n",
        "label_mapping = dict(zip(label_idx, prod_cat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "jOOJjt_jNYHX",
        "outputId": "a569b820-973c-4617-dfae-d6f928ef3e97"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label idx</th>\n",
              "      <th>product category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Home &amp; Kitchen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Health &amp; Personal Care</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Beauty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Sports &amp; Outdoors</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Books</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>Patio, Lawn &amp; Garden</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>Toys &amp; Games</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>CDs &amp; Vinyl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>Cell Phones &amp; Accessories</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>Grocery &amp; Gourmet Food</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label idx           product category\n",
              "0          0             Home & Kitchen\n",
              "1          1     Health & Personal Care\n",
              "2          2                     Beauty\n",
              "3          3          Sports & Outdoors\n",
              "4          4                      Books\n",
              "5          5       Patio, Lawn & Garden\n",
              "6          6               Toys & Games\n",
              "7          7                CDs & Vinyl\n",
              "8          8  Cell Phones & Accessories\n",
              "9          9     Grocery & Gourmet Food"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# lets see some of the product categories\n",
        "df[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0iVPXnCNZTt",
        "outputId": "4bba26e8-36aa-4c94-d020-27fda9b84b9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Counter({4: 668950, 7: 172199, 6: 158771, 3: 151061, 12: 131886, 2: 116043, 0: 114294, 8: 110796, 1: 109832, 13: 101541, 16: 83594, 21: 80795, 9: 67358, 10: 52345, 18: 49019, 24: 45406, 17: 42337, 5: 40715, 11: 32937, 42: 32500, 15: 26911, 20: 22575, 19: 17438, 23: 3653, 14: 3079, 25: 3024, 28: 1969, 29: 1561, 43: 1399, 22: 879, 36: 630, 44: 566, 26: 553, 37: 514, 32: 513, 31: 418, 30: 277, 27: 259, 34: 154, 38: 91, 41: 61, 35: 44, 39: 37, 33: 29, 45: 9, 40: 6, 46: 1})\n"
          ]
        }
      ],
      "source": [
        "# counting the numbers of samples for each category\n",
        "y = data.y.tolist()\n",
        "y = list(flatten(y))\n",
        "count_y = collections.Counter(y)\n",
        "print(count_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cq-mMPvtNFvg"
      },
      "source": [
        "# GraphSAGE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZsorPAmNa79"
      },
      "source": [
        "### Neighborhood Sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "Tw8w4V-AeSco"
      },
      "outputs": [],
      "source": [
        "dataset = Planetoid(path, 'Cora', transform=T.NormalizeFeatures())\n",
        "data = dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "g-wN4LHSNDWC"
      },
      "outputs": [],
      "source": [
        "class NeighborSampler(RawNeighborSampler):\n",
        "    def sample(self, batch):\n",
        "        batch = torch.tensor(batch)\n",
        "        row, col, _ = self.adj_t.coo()\n",
        "\n",
        "        # For each node in `batch`, we sample a direct neighbor (as positive\n",
        "        # example) and a random node (as negative example):\n",
        "        pos_batch = random_walk(row, col, batch, walk_length=1,\n",
        "                                coalesced=False)[:, 1]\n",
        "\n",
        "        neg_batch = torch.randint(0, self.adj_t.size(1), (batch.numel(), ),\n",
        "                                  dtype=torch.long)\n",
        "\n",
        "        batch = torch.cat([batch, pos_batch, neg_batch], dim=0)\n",
        "        return super().sample(batch)\n",
        "\n",
        "train_loader = NeighborSampler(data.edge_index, sizes=[10, 10], batch_size=256,\n",
        "                               shuffle=True, num_nodes=data.num_nodes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "S7ig035dNf_1"
      },
      "outputs": [],
      "source": [
        "class SAGE(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, num_layers):\n",
        "        super(SAGE, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.convs = nn.ModuleList()\n",
        "\n",
        "        for i in range(num_layers):\n",
        "            in_channels = in_channels if i == 0 else hidden_channels\n",
        "            self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
        "\n",
        "    def forward(self, x, adjs):\n",
        "        for i, (edge_index, _, size) in enumerate(adjs):\n",
        "            x_target = x[:size[1]]  # Target nodes are always placed first.\n",
        "            x = self.convs[i]((x, x_target), edge_index)\n",
        "            if i != self.num_layers - 1:\n",
        "                x = x.relu()\n",
        "                x = F.dropout(x, p=0.5, training=self.training)\n",
        "        return x\n",
        "\n",
        "    def full_forward(self, x, edge_index):\n",
        "        for i, conv in enumerate(self.convs):\n",
        "            x = conv(x, edge_index)\n",
        "            if i != self.num_layers - 1:\n",
        "                x = x.relu()\n",
        "                x = F.dropout(x, p=0.5, training=self.training)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prv0qiapNiyr",
        "outputId": "8c9cf933-f719-4bd5-8b81-57da46c7aeb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "# Set CUDA to run GPU if have, otherwise CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = SAGE(data.num_node_features, hidden_channels=64, num_layers=2)\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "x, edge_index = data.x.to(device), data.edge_index.to(device)\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ay_CSf6Nq6z",
        "outputId": "b060e543-433f-413d-93cf-3aa0d3c74923"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 001, Loss: 1.3867, Val: 0.3460, Test: 0.3320\n",
            "Epoch: 002, Loss: 1.3381, Val: 0.6380, Test: 0.6330\n",
            "Epoch: 003, Loss: 1.1698, Val: 0.6680, Test: 0.6490\n",
            "Epoch: 004, Loss: 1.0791, Val: 0.6740, Test: 0.6830\n",
            "Epoch: 005, Loss: 1.0406, Val: 0.6920, Test: 0.6850\n",
            "Epoch: 006, Loss: 1.0323, Val: 0.7100, Test: 0.7120\n",
            "Epoch: 007, Loss: 1.0132, Val: 0.7180, Test: 0.7230\n",
            "Epoch: 008, Loss: 1.0051, Val: 0.7180, Test: 0.7330\n",
            "Epoch: 009, Loss: 0.9803, Val: 0.7120, Test: 0.7400\n",
            "Epoch: 010, Loss: 0.9576, Val: 0.7000, Test: 0.7380\n",
            "Epoch: 011, Loss: 0.9522, Val: 0.7100, Test: 0.7420\n",
            "Epoch: 012, Loss: 0.9720, Val: 0.7120, Test: 0.7440\n",
            "Epoch: 013, Loss: 0.9787, Val: 0.7040, Test: 0.7460\n",
            "Epoch: 014, Loss: 0.9859, Val: 0.7000, Test: 0.7520\n",
            "Epoch: 015, Loss: 0.9452, Val: 0.7020, Test: 0.7550\n",
            "Epoch: 016, Loss: 0.9530, Val: 0.7180, Test: 0.7640\n",
            "Epoch: 017, Loss: 0.9540, Val: 0.7220, Test: 0.7630\n",
            "Epoch: 018, Loss: 0.9367, Val: 0.7300, Test: 0.7650\n",
            "Epoch: 019, Loss: 0.9320, Val: 0.7380, Test: 0.7650\n",
            "Epoch: 020, Loss: 0.9306, Val: 0.7520, Test: 0.7570\n",
            "Epoch: 021, Loss: 0.9320, Val: 0.7480, Test: 0.7600\n",
            "Epoch: 022, Loss: 0.9645, Val: 0.7440, Test: 0.7700\n",
            "Epoch: 023, Loss: 0.9244, Val: 0.7520, Test: 0.7660\n",
            "Epoch: 024, Loss: 0.9407, Val: 0.7520, Test: 0.7630\n",
            "Epoch: 025, Loss: 0.9252, Val: 0.7520, Test: 0.7690\n",
            "Epoch: 026, Loss: 0.9082, Val: 0.7520, Test: 0.7640\n",
            "Epoch: 027, Loss: 0.9065, Val: 0.7580, Test: 0.7670\n",
            "Epoch: 028, Loss: 0.9251, Val: 0.7660, Test: 0.7700\n",
            "Epoch: 029, Loss: 0.9163, Val: 0.7600, Test: 0.7670\n",
            "Epoch: 030, Loss: 0.9333, Val: 0.7660, Test: 0.7610\n",
            "Epoch: 031, Loss: 0.9079, Val: 0.7620, Test: 0.7630\n",
            "Epoch: 032, Loss: 0.9215, Val: 0.7540, Test: 0.7620\n",
            "Epoch: 033, Loss: 0.9096, Val: 0.7700, Test: 0.7710\n",
            "Epoch: 034, Loss: 0.9164, Val: 0.7600, Test: 0.7700\n",
            "Epoch: 035, Loss: 0.9135, Val: 0.7580, Test: 0.7730\n",
            "Epoch: 036, Loss: 0.9110, Val: 0.7660, Test: 0.7790\n",
            "Epoch: 037, Loss: 0.9144, Val: 0.7720, Test: 0.7710\n",
            "Epoch: 038, Loss: 0.9104, Val: 0.7640, Test: 0.7640\n",
            "Epoch: 039, Loss: 0.9015, Val: 0.7600, Test: 0.7650\n",
            "Epoch: 040, Loss: 0.9129, Val: 0.7660, Test: 0.7600\n",
            "Epoch: 041, Loss: 0.9147, Val: 0.7660, Test: 0.7590\n",
            "Epoch: 042, Loss: 0.9067, Val: 0.7680, Test: 0.7690\n",
            "Epoch: 043, Loss: 0.9041, Val: 0.7720, Test: 0.7570\n",
            "Epoch: 044, Loss: 0.9321, Val: 0.7680, Test: 0.7630\n",
            "Epoch: 045, Loss: 0.8998, Val: 0.7600, Test: 0.7570\n",
            "Epoch: 046, Loss: 0.9228, Val: 0.7540, Test: 0.7410\n",
            "Epoch: 047, Loss: 0.8890, Val: 0.7540, Test: 0.7500\n",
            "Epoch: 048, Loss: 0.9051, Val: 0.7500, Test: 0.7530\n",
            "Epoch: 049, Loss: 0.8879, Val: 0.7500, Test: 0.7620\n",
            "Epoch: 050, Loss: 0.9039, Val: 0.7480, Test: 0.7600\n"
          ]
        }
      ],
      "source": [
        "# Train and run model\n",
        "def train():\n",
        "    model.train()\n",
        "\n",
        "    total_loss = 0\n",
        "    for batch_size, n_id, adjs in train_loader:\n",
        "        # `adjs` holds a list of `(edge_index, e_id, size)` tuples.\n",
        "        adjs = [adj.to(device) for adj in adjs]\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        out = model(x[n_id], adjs)\n",
        "        out, pos_out, neg_out = out.split(out.size(0) // 3, dim=0)\n",
        "\n",
        "        pos_loss = F.logsigmoid((out * pos_out).sum(-1)).mean()\n",
        "        neg_loss = F.logsigmoid(-(out * neg_out).sum(-1)).mean()\n",
        "        loss = -pos_loss - neg_loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += float(loss) * out.size(0)\n",
        "\n",
        "    return total_loss / data.num_nodes\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test():\n",
        "    model.eval()\n",
        "    out = model.full_forward(x, edge_index).cpu()\n",
        "\n",
        "    clf = LogisticRegression()\n",
        "    clf.fit(out[data.train_mask], data.y[data.train_mask])\n",
        "\n",
        "    val_acc = clf.score(out[data.val_mask], data.y[data.val_mask])\n",
        "    test_acc = clf.score(out[data.test_mask], data.y[data.test_mask])\n",
        "\n",
        "    return val_acc, test_acc\n",
        "\n",
        "\n",
        "for epoch in range(1, 51):\n",
        "    loss = train()\n",
        "    val_acc, test_acc = test()\n",
        "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, '\n",
        "          f'Val: {val_acc:.4f}, Test: {test_acc:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8n1ZWLstN2aj",
        "outputId": "9fb19dca-6aae-4ac7-d3ab-b883fd0f5a1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SAGE(\n",
            "  (convs): ModuleList(\n",
            "    (0): SAGEConv(1433, 64, aggr=mean)\n",
            "    (1): SAGEConv(64, 64, aggr=mean)\n",
            "  )\n",
            ")\n",
            "Model's state_dict:\n",
            "convs.0.lin_l.weight \t torch.Size([64, 1433])\n",
            "convs.0.lin_l.bias \t torch.Size([64])\n",
            "convs.0.lin_r.weight \t torch.Size([64, 1433])\n",
            "convs.1.lin_l.weight \t torch.Size([64, 64])\n",
            "convs.1.lin_l.bias \t torch.Size([64])\n",
            "convs.1.lin_r.weight \t torch.Size([64, 64])\n"
          ]
        }
      ],
      "source": [
        "# Print model info\n",
        "print(model)\n",
        "\n",
        "# Print model's state_dict\n",
        "print(\"Model's state_dict:\")\n",
        "for param_tensor in model.state_dict():\n",
        "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "FrKC9jglN9W2"
      },
      "outputs": [],
      "source": [
        "# saving model\n",
        "fp = 'data/model.pt'\n",
        "\n",
        "torch.save(model, './model.pt')\n",
        "torch.save(model, fp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGkJ9AuCN_Qm"
      },
      "source": [
        "# GraphSAINT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4SMcWVxWkCD"
      },
      "source": [
        "# Retrieve the data and check graph information\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFkComlYWkzr",
        "outputId": "f9125963-ef64-4281-c011-27cfaa550ce3"
      },
      "outputs": [],
      "source": [
        "path = osp.join('data', 'cora')\n",
        "dataset = Planetoid(path,name = 'cora')\n",
        "data = dataset[0]\n",
        "row, col = data.edge_index\n",
        "data.edge_weight = 1. / degree(col, data.num_nodes)[col]  # Norm by in-degree."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwAf-GlZWqK6",
        "outputId": "48eccbaf-b77d-4eea-a89a-ef73185806a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of nodes in the graph: 2708\n",
            "Number of edges in the graph: 10556\n",
            "Node feature matrix with shape: torch.Size([2708, 1433])\n",
            "Graph connectivity in COO format with shape: torch.Size([2, 10556])\n",
            "Target to train against : torch.Size([2708])\n",
            "Node feature length 1433\n"
          ]
        }
      ],
      "source": [
        "# lets check some graph statistics of graph\n",
        "print(\"Number of nodes in the graph:\", data.num_nodes)\n",
        "print(\"Number of edges in the graph:\", data.num_edges)\n",
        "print(\"Node feature matrix with shape:\", data.x.shape) # [num_nodes, num_node_features]\n",
        "print(\"Graph connectivity in COO format with shape:\", data.edge_index.shape) # [2, num_edges]\n",
        "print(\"Target to train against :\", data.y.shape)\n",
        "print(\"Node feature length\", dataset.num_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2kIRjO3WsaZ",
        "outputId": "5c98831d-69e9-4407-8f5d-7e275ca66921"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Arguments: Namespace(use_normalization=False, f=None)\n",
            "Data loader created: <torch_geometric.loader.graph_saint.GraphSAINTRandomWalkSampler object at 0x000001F3DBF70AD0>\n"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "import sys\n",
        "import os\n",
        "import os.path as osp\n",
        "from ogb.nodeproppred import PygNodePropPredDataset\n",
        "import torch\n",
        "import torch_geometric.data.data\n",
        "import torch_geometric.data.storage\n",
        "from torch_geometric.loader import GraphSAINTRandomWalkSampler\n",
        "\n",
        "# Check if running in Jupyter\n",
        "def in_notebook():\n",
        "    try:\n",
        "        from IPython import get_ipython\n",
        "        return get_ipython() is not None\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "# Set up argparse to handle Jupyter environment\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--use_normalization', action='store_true', help='Enable normalization')\n",
        "parser.add_argument('-f', required=False, help='Jupyter kernel argument (ignored)')  # Explicitly allow -f\n",
        "\n",
        "# Parse arguments differently in Jupyter\n",
        "if in_notebook():\n",
        "    # In Jupyter, pass empty args to avoid kernel arguments\n",
        "    args = parser.parse_args(args=[])\n",
        "else:\n",
        "    args = parser.parse_args()\n",
        "\n",
        "# Print parsed arguments for verification\n",
        "print(\"Arguments:\", args)\n",
        "\n",
        "# Load dataset (from previous fixes)\n",
        "path = osp.join('data', 'Reddit')\n",
        "os.makedirs(path, exist_ok=True)\n",
        "\n",
        "# Allowlist necessary classes for dataset loading\n",
        "torch.serialization.add_safe_globals([\n",
        "    torch_geometric.data.data.DataEdgeAttr,\n",
        "    torch_geometric.data.data.DataTensorAttr,\n",
        "    torch_geometric.data.Data,\n",
        "    torch_geometric.data.storage.GlobalStorage\n",
        "])\n",
        "\n",
        "# Load the dataset\n",
        "dataset = PygNodePropPredDataset('ogbn-products', path)\n",
        "data = dataset[0]  # Get the first graph\n",
        "\n",
        "train_idx = split_idx['train']\n",
        "valid_idx = split_idx['valid']\n",
        "test_idx = split_idx['test']\n",
        "\n",
        "data.train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "data.train_mask[train_idx] = True\n",
        "\n",
        "data.val_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "data.val_mask[valid_idx] = True\n",
        "\n",
        "data.test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "data.test_mask[test_idx] = True\n",
        "\n",
        "# Initialize GraphSAINTRandomWalkSampler\n",
        "loader = GraphSAINTRandomWalkSampler(\n",
        "    data,\n",
        "    batch_size=16,\n",
        "    walk_length=2,\n",
        "    num_steps=5,\n",
        "    sample_coverage=10,\n",
        "    save_dir=dataset.processed_dir\n",
        ")\n",
        "\n",
        "# Verify the loader\n",
        "print(\"Data loader created:\", loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "3BSOQKsnWtyJ"
      },
      "outputs": [],
      "source": [
        "# Model\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        in_channels = dataset.num_node_features\n",
        "        out_channels = dataset.num_classes\n",
        "        self.conv1 = GraphConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GraphConv(hidden_channels, hidden_channels)\n",
        "        self.conv3 = GraphConv(hidden_channels, hidden_channels)\n",
        "        self.lin = torch.nn.Linear(3 * hidden_channels, out_channels)\n",
        "\n",
        "    def set_aggr(self, aggr):\n",
        "        self.conv1.aggr = aggr\n",
        "        self.conv2.aggr = aggr\n",
        "        self.conv3.aggr = aggr\n",
        "\n",
        "    def forward(self, x0, edge_index, edge_weight=None):\n",
        "        x1 = F.relu(self.conv1(x0, edge_index, edge_weight))\n",
        "        x1 = F.dropout(x1, p=0.2, training=self.training)\n",
        "        x2 = F.relu(self.conv2(x1, edge_index, edge_weight))\n",
        "        x2 = F.dropout(x2, p=0.2, training=self.training)\n",
        "        x3 = F.relu(self.conv3(x2, edge_index, edge_weight))\n",
        "        x3 = F.dropout(x3, p=0.2, training=self.training)\n",
        "        x = torch.cat([x1, x2, x3], dim=-1)\n",
        "        x = self.lin(x)\n",
        "        return x.log_softmax(dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "okTgcGQ0WwIp"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = Net(hidden_channels=64).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGyizBeqWxZJ"
      },
      "outputs": [],
      "source": [
        "def train():\n",
        "    model.train()\n",
        "    model.set_aggr('add' if args.use_normalization else 'mean')\n",
        "\n",
        "    total_loss = total_examples = 0\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if args.use_normalization:\n",
        "            edge_weight = data.edge_norm * data.edge_weight\n",
        "            out = model(data.x, data.edge_index, edge_weight)\n",
        "            loss = F.nll_loss(out, data.y, reduction='none')\n",
        "            loss = (loss * data.node_norm)[data.train_mask].sum()\n",
        "        else:\n",
        "            out = model(data.x, data.edge_index)\n",
        "            # Use .squeeze() to remove the second dimension of data.y\n",
        "            loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask].squeeze())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * data.num_nodes\n",
        "        total_examples += data.num_nodes\n",
        "    return total_loss / total_examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "DFNsHaPjWy2q"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def test():\n",
        "    model.eval()\n",
        "    model.set_aggr('mean')\n",
        "\n",
        "    out = model(data.x.to(device), data.edge_index.to(device))\n",
        "    pred = out.argmax(dim=-1)\n",
        "    correct = pred.eq(data.y.to(device))\n",
        "\n",
        "    accs = []\n",
        "    for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n",
        "        accs.append(correct[mask].sum().item() / mask.sum().item())\n",
        "    return accs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "au4yZZWqW0HZ",
        "outputId": "2031d0ab-da70-4a26-df3c-c5341862310b"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "0D or 1D target tensor expected, multi-target not supported",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[105]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m15\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     loss = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m     accs = test()\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Train: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccs[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      5\u001b[39m           \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mVal: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccs[\u001b[32m1\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Test: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccs[\u001b[32m2\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[103]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     16\u001b[39m     out = model(data.x, data.edge_index)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     loss = \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnll_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_mask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_mask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m loss.backward()\n\u001b[32m     20\u001b[39m optimizer.step()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mf:\\Thien\\course_graph_2025\\venv\\Lib\\site-packages\\torch\\nn\\functional.py:3147\u001b[39m, in \u001b[36mnll_loss\u001b[39m\u001b[34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[39m\n\u001b[32m   3145\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3146\u001b[39m     reduction = _Reduction.legacy_get_string(size_average, reduce)\n\u001b[32m-> \u001b[39m\u001b[32m3147\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_nn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnll_loss_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3148\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\n\u001b[32m   3149\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mRuntimeError\u001b[39m: 0D or 1D target tensor expected, multi-target not supported"
          ]
        }
      ],
      "source": [
        "for epoch in range(15):\n",
        "    loss = train()\n",
        "    accs = test()\n",
        "    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}, Train: {accs[0]:.4f}, '\n",
        "          f'Val: {accs[1]:.4f}, Test: {accs[2]:.4f}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
